{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from src.data_generation import generate_data\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# load config using hydra\n",
    "with initialize(version_base=None, config_path=\"config\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data.N = 50\n",
    "cfg.graph.graph_type = 'ER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "# generate data and move to device\n",
    "X, y, graph_filters_flat, weight_matrix, filter_coefficients = [d.to(device) for d in generate_data(cfg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from src.utils import get_each_graph_filter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class TIRSO:\n",
    "    def __init__(self, N, hyperparams, device):\n",
    "        self.N = N\n",
    "        self.set_hyperparameters(hyperparams)\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        N, P = self.N, self._P\n",
    "        self.m_A_initial = np.zeros((N, N * P))\n",
    "\n",
    "    def set_hyperparameters(self, hyperparams):\n",
    "        for param, value in hyperparams.items():\n",
    "            setattr(self, f\"_{param}\", value)\n",
    "        self._mu = 1 - self._gamma\n",
    "        \n",
    "    def run(self, y, weight_matrix=None, **kwargs):\n",
    "        # This function computes an estimate via TISO\n",
    "\n",
    "        results = {\n",
    "            'pred_error': [], 'w_error': [], 'matrices': [],\n",
    "            'percentage_correct_elements': [], 'num_non_zero_elements': [],\n",
    "            'p_miss': [], 'p_false_alarm': [], 'pred_error_recursive_moving_average': [1]\n",
    "        }\n",
    "\n",
    "        lowest_error = 1e10\n",
    "        a_prev = self.m_A_initial  # size N X NP\n",
    "\n",
    "        # init params\n",
    "        y = np.array(y)\n",
    "        weight_matrix = np.array(weight_matrix) if weight_matrix is not None else None\n",
    "        m_y = y[:, :, 0].T\n",
    "        N, T = m_y.shape\n",
    "        \n",
    "        assert a_prev.shape[0] == N and a_prev.shape[1] == N * self._P, 'A_initial should have of size N X NP'\n",
    "        \n",
    "        Phi_prev = self._sigma**2 * np.eye(N * self._P)  # initializing Phi\n",
    "        r_prev = np.zeros((N * self._P, N))  # r has NP X N size to avoid transpose \n",
    "        m_r = np.zeros((N * self._P, N))\n",
    "        t_A = np.zeros((N, N * self._P, T))\n",
    "\n",
    "        with tqdm(range(self._P, T)) as pbar:\n",
    "            for t in pbar:  # in paper, t=P,...\n",
    "                # receive data y[t]\n",
    "                # form g[t] via g[t]= vec([y[t-1],...,y[t-P]]^T)\n",
    "                ma_error = results['pred_error_recursive_moving_average'][-1]\n",
    "\n",
    "                ##################################\n",
    "                ######### CHECK CONVERGENCE ######\n",
    "                ##################################\n",
    "                if lowest_error != 0:\n",
    "                    relative_improvement = (lowest_error - ma_error) / lowest_error\n",
    "                else:\n",
    "                    relative_improvement = float('inf') if ma_error < lowest_error else 0\n",
    "\n",
    "                if relative_improvement > self._min_delta_percent:\n",
    "                    lowest_error = ma_error\n",
    "                    patience_left = self._patience\n",
    "                else:\n",
    "                    if t > self._patience:\n",
    "                        patience_left -= 1\n",
    "\n",
    "                if patience_left == 0:\n",
    "                    break\n",
    "                    \n",
    "                ##################################\n",
    "                ######## TIRSO ALGORITHM ##########\n",
    "                ##################################\n",
    "                y_prev = m_y[:, t - self._P:t]\n",
    "                aux = np.fliplr(y_prev).T\n",
    "                g = aux.flatten()\n",
    "\n",
    "                # compute stepsize\n",
    "                R = np.outer(g, g)\n",
    "                eigs = torch.lobpcg(torch.tensor(R), largest=True)\n",
    "                stepsize = 2 / (eigs[0].item())\n",
    "                stepsize /= (np.linalg.norm(g, ord=2)**2 + self._epsilon)\n",
    "\n",
    "                # update Phi\n",
    "                Phi_t = self._gamma * Phi_prev + self._mu * R\n",
    "                \n",
    "                if self._b_trace == 1:\n",
    "                    if self._b_diminishing == 1:\n",
    "                        stepsize = 1 / (np.trace(Phi_t) * np.sqrt(t))\n",
    "                    else:\n",
    "                        stepsize = 1 / np.trace(Phi_t)\n",
    "\n",
    "                for n in range(N):\n",
    "                    # update r_n\n",
    "                    m_r[:, n] = self._gamma * r_prev[:, n] + self._mu * m_y[n, t] * g\n",
    "                    grad_n = Phi_t @ a_prev[n, :].T - m_r[:, n]  # v_n in the paper\n",
    "\n",
    "                    for nprime in range(N):\n",
    "                        groupindices = slice((nprime - 1) * self._P, nprime * self._P)  # n,n' group indices\n",
    "                        af_nnprime = a_prev[n, groupindices] - stepsize * grad_n[groupindices]\n",
    "                        \n",
    "                        if n != nprime:\n",
    "                            t_A[n, groupindices, t] = np.maximum(0, (1 - (stepsize * self._lambda) / (np.linalg.norm(af_nnprime) + self._epsilon))) * af_nnprime  # indicator rem\n",
    "                        else:\n",
    "                            t_A[n, groupindices, t] = af_nnprime\n",
    "                \n",
    "                # to store A, Phi, and r_n\n",
    "                a_prev = t_A[:, :, t]\n",
    "                Phi_prev = Phi_t\n",
    "                r_prev = m_r\n",
    "\n",
    "                ##################################\n",
    "                ######### COMPUTE W ##############\n",
    "                ##################################\n",
    "\n",
    "                # compute the causal graph from the VAR parameters as described in paper\n",
    "                psi = get_each_graph_filter(torch.tensor(a_prev), cfg.data.N, cfg.data.P).numpy()\n",
    "                causal = ((psi == 0).sum(axis=1)) != cfg.data.P\n",
    "                W = np.linalg.norm(psi, ord=2, axis=1) * causal  # use magnitude of psi as weights\n",
    "                \n",
    "                ##################################\n",
    "                ######### COMPUTE ERRORS #########\n",
    "                ##################################\n",
    "\n",
    "                # Compute squared error of signal forecast from graph filters\n",
    "                e = m_y[:, t] - a_prev @ g\n",
    "                norm_error = np.linalg.norm(e)**2 / np.linalg.norm(m_y[:, t])**2\n",
    "                results['pred_error'].append(norm_error)\n",
    "                ma_error = self._ma_alpha * norm_error + (1 - self._ma_alpha) * results['pred_error_recursive_moving_average'][-1]\n",
    "                results['pred_error_recursive_moving_average'].append(ma_error)\n",
    "        \n",
    "                # Compute squared error of W estimation\n",
    "                if weight_matrix is not None:\n",
    "                    weight_matrix_error = weight_matrix - W\n",
    "                    norm_w_error = np.linalg.norm(weight_matrix_error)**2 / np.linalg.norm(weight_matrix)**2\n",
    "                    results['w_error'].append(norm_w_error)\n",
    "                    results['num_non_zero_elements'].append((W != 0).sum())\n",
    "\n",
    "                    # compute the percentage of elements correctly identified in W\n",
    "                    total = (weight_matrix != 0).sum()\n",
    "                    frac = ((W != 0) * (weight_matrix != 0)).sum() / total\n",
    "                    results['percentage_correct_elements'].append(frac)\n",
    "\n",
    "                    # save results for p_miss: probability of missing a non-zero element in W\n",
    "                    results['p_miss'].append(((W == 0) * (weight_matrix != 0)).sum().item() / (weight_matrix != 0).sum().item())\n",
    "                    results['p_false_alarm'].append(((W != 0) * (weight_matrix == 0)).sum().item() / (weight_matrix == 0).sum().item())\n",
    "            \n",
    "                results['matrices'].append(W)\n",
    "                pbar.set_postfix({'MA y error': ma_error})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 397/9997 [01:14<30:07,  5.31it/s, MA y error=0.992]\n"
     ]
    }
   ],
   "source": [
    "y_in = y[:, :, 0].cpu().numpy()\n",
    "\n",
    "hyperparams = {\n",
    "    'P': 3,\n",
    "    'lambda': 0.1,\n",
    "    'b_trace': 0,\n",
    "    'b_diminishing': 0,\n",
    "    'sigma': 0.005,\n",
    "    'gamma': 0.99,\n",
    "    'epsilon': 1e-3,\n",
    "    'ma_alpha': 0.005,\n",
    "    'patience': 200,\n",
    "    'min_delta_percent': 0.01\n",
    "}\n",
    "model = TIRSO(cfg.data.N, hyperparams, device)\n",
    "model_inputs = {\n",
    "    'y': y,\n",
    "    'weight_matrix': weight_matrix,\n",
    "    'filter_coefficients': filter_coefficients,\n",
    "    'graph_filters_flat': graph_filters_flat\n",
    "}\n",
    "results = model.run(**model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nmse_pred_alg1: 0.988920040\n",
      "\n",
      "nmse_w_alg1: 1.001351981\n",
      "\n",
      "pce_alg1: 1.000000000\n",
      "\n",
      "p_miss_alg1: 0.000000000\n",
      "\n",
      "p_false_alarm_alg1: 1.000000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patience=200\n",
    "pred_error = np.array(results['pred_error'])\n",
    "alg1_in_steady_state = np.zeros_like(pred_error, dtype=bool)\n",
    "alg1_in_steady_state[-patience:] = True\n",
    "\n",
    "metrics = {\n",
    "    'nmse_pred': np.array(results['pred_error']),\n",
    "    'nmse_w': np.array(results['w_error']),\n",
    "    'pce': np.array(results['percentage_correct_elements']),\n",
    "    'p_miss': np.array(results['p_miss']),\n",
    "    'p_false_alarm': np.array(results['p_false_alarm'])\n",
    "}\n",
    "\n",
    "algorithms = {\n",
    "    'alg1': alg1_in_steady_state\n",
    "}\n",
    "\n",
    "for alg_name, alg_state in algorithms.items():\n",
    "    for metric_name, metric_values in metrics.items():\n",
    "        mean_value = np.mean(metric_values[alg_state])\n",
    "        print(f\"{metric_name}_{alg_name}: {mean_value:.9f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
